{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lq4rGk3XN_h"
      },
      "source": [
        "This script gets data from Alpha Vantage API, and contains:\n",
        "\n",
        "For 50 of the most traded tickers/companies:\n",
        "\n",
        " - news articles (earliest is 2019 if available, and onwards)\n",
        " - earning call transcripts (Q1-4 2024),\n",
        " - daily stock price (past 100 days)\n",
        "\n",
        "News articles in specific topics:\n",
        " - ‘ipo’, ‘earnings’, ‘mergers_and_acquisitions’, ‘economy_macro’, ‘economy_fiscal’, ‘economy_monetary’, ‘technology’, ‘finance’\n",
        "\n",
        "Economic indicators (i think its only most recent data):\n",
        " - GDP, unemployment, inflation, interest rates\n",
        "\n",
        "Data is in raw json format, needs extraction and re-organizing for model inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kimwVSjZXN_i",
        "outputId": "98be930d-c456-4937-9b26-9f516a1d171b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching SPY...\n",
            "Fetching QQQ...\n",
            "Fetching DIA...\n",
            "Fetching AAPL...\n",
            "Fetching MSFT...\n",
            "Fetching NVDA...\n",
            "Fetching GOOGL...\n",
            "Fetching GOOG...\n",
            "Fetching SAP...\n",
            "Fetching META...\n",
            "Fetching PLTR...\n",
            "Fetching AMD...\n",
            "Fetching INTC...\n",
            "Fetching TSLA...\n",
            "Fetching AMZN...\n",
            "Fetching WMT...\n",
            "Fetching COST...\n",
            "Fetching JPM...\n",
            "Fetching GS...\n",
            "Fetching MS...\n",
            "Fetching HOOD...\n",
            "Fetching UNH...\n",
            "Fetching PFE...\n",
            "Fetching TEM...\n",
            "Fetching ACN...\n",
            "Fetching IBM...\n",
            "Fetching XOM...\n",
            "Fetching SHEL...\n",
            "Fetching CVX...\n",
            "Fetching BRK-A...\n",
            "Fetching MSTR...\n",
            "Fetching NFLX...\n",
            "Fetching V...\n",
            "Fetching CSCO...\n",
            "Fetching LLY...\n",
            "Fetching TME...\n",
            "Fetching NVO...\n",
            "Fetching NOW...\n",
            "Fetching SNOW...\n",
            "Fetching HD...\n",
            "Fetching COR...\n",
            "Fetching HMC...\n",
            "Fetching PANW...\n",
            "Fetching MRK...\n",
            "Fetching ORCL...\n",
            "Fetching BAC...\n",
            "Fetching MA...\n",
            "Fetching RDFN...\n",
            "Fetching VNET...\n",
            "Fetching AVGO...\n",
            "Fetching topic: ipo...\n",
            "Fetching topic: earnings...\n",
            "Fetching topic: mergers_and_acquisitions...\n",
            "Fetching topic: economy_macro...\n",
            "Fetching topic: economy_fiscal...\n",
            "Fetching topic: economy_monetary...\n",
            "Fetching topic: technology...\n",
            "Fetching topic: finance...\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: 'Price_Prediction_FinBERT-LSTM'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 174\u001b[39m\n\u001b[32m    171\u001b[39m economic_data = get_economic_indicators()\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# Save to CSV files\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_prices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPrice_Prediction_FinBERT-LSTM/alpha_stock_prices.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m pd.DataFrame(all_news).to_csv(\u001b[33m\"\u001b[39m\u001b[33mPrice_Prediction_FinBERT-LSTM/alpha_ticker_news.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    176\u001b[39m pd.DataFrame(all_earnings).to_csv(\u001b[33m\"\u001b[39m\u001b[33mPrice_Prediction_FinBERT-LSTM/alpha_earnings_calls.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/stockpred/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/stockpred/lib/python3.12/site-packages/pandas/core/generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/stockpred/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/stockpred/lib/python3.12/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/stockpred/lib/python3.12/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/stockpred/lib/python3.12/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'Price_Prediction_FinBERT-LSTM'"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "# List of stock tickers and topics\n",
        "tickers = [\n",
        "    \"SPY\", \"QQQ\", \"DIA\", \"AAPL\", \"MSFT\", \"NVDA\", \"GOOGL\", \"GOOG\", \"SAP\", \"META\", \"PLTR\", \"AMD\", \"INTC\",\n",
        "    \"TSLA\", \"AMZN\", \"WMT\", \"COST\", \"JPM\", \"GS\", \"MS\", \"HOOD\", \"UNH\", \"PFE\", \"TEM\", \"ACN\", \"IBM\",\n",
        "    \"XOM\", \"SHEL\", \"CVX\", \"BRK-A\", \"MSTR\", \"NFLX\", \"V\", \"CSCO\", \"LLY\", \"TME\", \"NVO\", \"NOW\", 'SNOW', 'HD', 'COR', 'HMC', 'PANW', 'MRK', 'ORCL', 'BAC', 'MA', 'RDFN', 'VNET', 'AVGO'\n",
        "]\n",
        "topics = ['ipo', 'earnings', 'mergers_and_acquisitions', 'economy_macro', 'economy_fiscal', 'economy_monetary', 'technology', 'finance']\n",
        "\n",
        "ALPHA_VANTAGE_API_KEY = \"83OBSO8TRSM5ASNS\"\n",
        "\n",
        "# Helper functions\n",
        "def get_news_from_alphavantage(ticker):\n",
        "    if ticker in (\"SPY\", \"QQQ\", \"DIA\"):\n",
        "        return []\n",
        "    url = \"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"NEWS_SENTIMENT\",\n",
        "        \"tickers\": ticker,\n",
        "        \"time_from\": \"20190101T0000\",\n",
        "        \"limit\": 1000,\n",
        "        \"apikey\": ALPHA_VANTAGE_API_KEY\n",
        "    }\n",
        "    r = requests.get(url, params=params)\n",
        "    if r.status_code == 200:\n",
        "        return r.json().get(\"feed\", [])\n",
        "    return []\n",
        "\n",
        "def get_news_by_topic_from_alphavantage(topic):\n",
        "    url = \"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"NEWS_SENTIMENT\",\n",
        "        \"topics\": topic,\n",
        "        \"time_from\": \"20190101T0000\",\n",
        "        \"limit\": 1000,\n",
        "        \"apikey\": ALPHA_VANTAGE_API_KEY\n",
        "    }\n",
        "    r = requests.get(url, params=params)\n",
        "    if r.status_code == 200:\n",
        "        return r.json().get(\"feed\", [])\n",
        "    return []\n",
        "\n",
        "def get_stock_prices_from_alphavantage(ticker):\n",
        "    url = \"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"TIME_SERIES_DAILY\",\n",
        "        \"symbol\": ticker,\n",
        "        \"outputsize\": \"compact\",\n",
        "        \"apikey\": ALPHA_VANTAGE_API_KEY\n",
        "    }\n",
        "    r = requests.get(url, params=params)\n",
        "    if r.status_code == 200:\n",
        "        raw = r.json().get(\"Time Series (Daily)\", {})\n",
        "        return [{\n",
        "            \"ticker\": ticker,\n",
        "            \"date\": date,\n",
        "            \"open\": float(values[\"1. open\"]),\n",
        "            \"high\": float(values[\"2. high\"]),\n",
        "            \"low\": float(values[\"3. low\"]),\n",
        "            \"close\": float(values[\"4. close\"]),\n",
        "            \"volume\": int(values[\"5. volume\"])\n",
        "        } for date, values in raw.items()]\n",
        "    return []\n",
        "\n",
        "def get_earnings_from_alphavantage(ticker):\n",
        "    if ticker in (\"SPY\", \"QQQ\", \"DIA\"):\n",
        "        return []\n",
        "    base_url = \"https://www.alphavantage.co/query\"\n",
        "    quarters = ['2025Q1']\n",
        "    earnings = []\n",
        "    for q in quarters:\n",
        "        params = {\n",
        "            \"function\": \"EARNINGS_CALL_TRANSCRIPT\",\n",
        "            \"symbol\": ticker,\n",
        "            \"quarter\": q,\n",
        "            \"apikey\": ALPHA_VANTAGE_API_KEY\n",
        "        }\n",
        "        r = requests.get(base_url, params=params)\n",
        "        if r.status_code == 200:\n",
        "            data = r.json()\n",
        "            if 'symbol' in data and 'summary' in data:\n",
        "                earnings.append({\n",
        "                    \"ticker\": ticker,\n",
        "                    \"quarter\": q,\n",
        "                    \"summary\": data.get(\"summary\", \"\"),\n",
        "                    \"content\": data.get(\"content\", \"\")\n",
        "                })\n",
        "    return earnings\n",
        "\n",
        "def get_economic_indicators():\n",
        "    indicators = [\"REAL_GDP\", \"FEDERAL_FUNDS_RATE\", \"INFLATION\", \"UNEMPLOYMENT\"]\n",
        "    rows = []\n",
        "    for indicator in indicators:\n",
        "        url = \"https://www.alphavantage.co/query\"\n",
        "        params = {\"function\": indicator, \"apikey\": ALPHA_VANTAGE_API_KEY}\n",
        "        r = requests.get(url, params=params)\n",
        "        if r.status_code == 200:\n",
        "            data = r.json().get(\"data\", [])\n",
        "            for item in data:\n",
        "                rows.append({\n",
        "                    \"indicator\": indicator,\n",
        "                    \"date\": item.get(\"date\"),\n",
        "                    \"value\": item.get(\"value\")\n",
        "                })\n",
        "    return rows\n",
        "\n",
        "# Data collection\n",
        "all_prices, all_news, all_earnings, all_topic_news = [], [], [], []\n",
        "\n",
        "for ticker in tickers:\n",
        "    print(f\"Fetching {ticker}...\")\n",
        "    prices = get_stock_prices_from_alphavantage(ticker)\n",
        "    news = get_news_from_alphavantage(ticker)\n",
        "    earnings = get_earnings_from_alphavantage(ticker)\n",
        "\n",
        "    all_prices.extend(prices)\n",
        "    all_news.extend([{\n",
        "        \"ticker\": ticker,\n",
        "        \"title\": article.get(\"title\"),\n",
        "        \"summary\": article.get(\"summary\"),\n",
        "        \"sentiment\": article.get(\"overall_sentiment_label\"),\n",
        "        \"score\": article.get(\"overall_sentiment_score\"),\n",
        "        \"date\": article.get(\"time_published\")\n",
        "    } for article in news])\n",
        "    for quarter in earnings:\n",
        "        if \"Q1\" in earnings.get(\"quarter\"):\n",
        "            dates = [\"2025-04-20\", \"2025-04-22\", \"2025-04-24\", \"2025-04-26\"]\n",
        "            date = random.choice(dates)\n",
        "        for transcript in quarter:\n",
        "            for part in transcript:\n",
        "                sentiment = float(part.get(\"sentiment\"))\n",
        "                if sentiment <= -0.35:\n",
        "                    sentiment = \"Bearish\"\n",
        "                elif sentiment <= -0.15:\n",
        "                    sentiment = \"Somewhat-Bearish\"\n",
        "                elif sentiment <= 0.15:\n",
        "                    sentiment = \"Neutral\"\n",
        "                elif sentiment < 0.35:\n",
        "                    sentiment = \"Somewhat-Bullish\"\n",
        "                else:\n",
        "                    sentiment = \"Bullish\"\n",
        "                all_earnings.extend([{\n",
        "                    'ticker': ticker,\n",
        "                    \"title\": part.get(\"title\"),\n",
        "                    \"summary\": part.get(\"content\"),\n",
        "                    \"sentiment\": sentiment,\n",
        "                    \"score\": part.get(\"sentiment\"),\n",
        "                    \"date\": date\n",
        "                }])\n",
        "    time.sleep(15)\n",
        "\n",
        "# Topics\n",
        "for topic in topics:\n",
        "    print(f\"Fetching topic: {topic}...\")\n",
        "    news = get_news_by_topic_from_alphavantage(topic)\n",
        "    all_topic_news.extend([{\n",
        "        \"topic\": topic,\n",
        "        \"title\": article.get(\"title\"),\n",
        "        \"summary\": article.get(\"summary\"),\n",
        "        \"sentiment\": article.get(\"overall_sentiment_label\"),\n",
        "        \"score\": article.get(\"overall_sentiment_score\"),\n",
        "        \"date\": article.get(\"time_published\")\n",
        "    } for article in news])\n",
        "    time.sleep(10)\n",
        "\n",
        "# Economic indicators\n",
        "economic_data = get_economic_indicators()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All data saved to CSV files.\n"
          ]
        }
      ],
      "source": [
        "# Save to CSV files\n",
        "pd.DataFrame(all_prices).to_csv(\"../Price_Prediction_FinBERT-LSTM/alpha_stock_prices.csv\", index=False)\n",
        "pd.DataFrame(all_news).to_csv(\"../Price_Prediction_FinBERT-LSTM/alpha_ticker_news.csv\", index=False)\n",
        "pd.DataFrame(all_earnings).to_csv(\"../Price_Prediction_FinBERT-LSTM/alpha_earnings_calls.csv\", index=False)\n",
        "pd.DataFrame(all_topic_news).to_csv(\"../Price_Prediction_FinBERT-LSTM/alpha_topic_news.csv\", index=False)\n",
        "pd.DataFrame(economic_data).to_csv(\"../Price_Prediction_FinBERT-LSTM/alpha_economic_indicators.csv\", index=False)\n",
        "\n",
        "print(\"✅ All data saved to CSV files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(earnings)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
